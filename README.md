<div align="center">
<img src="https://github.com/user-attachments/assets/f965fd42-2a95-4552-9b5f-465fc4037a91" width="500" /><br />
<em>An open source real-time AI inference engine for seamless scaling</em>
</div>

# This code will be released soon!

# Installation

```sh
pip install taproot
```

## Installing Tasks

Some tasks are available immediately, but most tasks required additional packages and files. Install these tasks with `taproot install [task:model]+`, e.g: 

```sh
taproot install image-generation:stable-diffusion-xl
```

# Usage

## Introspecting Tasks

From the command line, execute `taproot tasks` to see all tasks and their availability status, or `taproot info` for individual task information. For example:

```sh
taproot info image-generation stable-diffusion-xl

Stable Diffusion XL Image Generation (image-generation:stable-diffusion-xl, available)
    Generate an image from text and/or images using a stable diffusion XL model.
Hardware Requirements:                  
    GPU Required for Optimal Performance                                           
    Floating Point Precision: half                                                 
    Minimum Memory (CPU RAM) Required: 231.71 MB     
    Minimum Memory (GPU VRAM) Required: 7.58 GB               
Author:                          
    Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach
    Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023
    https://arxiv.org/abs/2307.01952                                               
License:
    OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)
    ✅ Attribution Required
    ✅ Derivatives Allowed
    ✅ Redistribution Allowed
    ✅ Copyleft (Share-Alike) Required
    ✅ Commercial Use Allowed
    ✅ Hosting Allowed
Files:                                                                             
    image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB) [downloaded]
    image-generation-stable-diffusion-xl-base-unet.fp16.safetensors (5.14 GB) [downloaded]
    text-encoding-clip-vit-l.bf16.safetensors (246.14 MB) [downloaded]
    text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB) [downloaded]
    text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB) [downloaded]
    text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B) [downloaded]
    text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB) [downloaded]
    text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB) [downloaded]
    text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B) [downloaded]
    text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB) [downloaded]
    Total File Size: 7.11 GB
Required packages:
    pil~=9.5 [installed]
    torch<2.5,>=2.4 [installed]
    numpy~=1.22 [installed]
    diffusers>=0.29 [installed]
    torchvision<0.20,>=0.19 [installed]
    transformers>=4.41 [installed]
    safetensors~=0.4 [installed]
    accelerate~=1.0 [installed]
    sentencepiece~=0.2 [installed]
    compel~=2.0 [installed]
    peft~=0.13 [installed]
Signature:
    prompt: Union[str, List[str]], required
    prompt_2: Union[str, List[str]], default: None
    negative_prompt: Union[str, List[str]], default: None
    negative_prompt_2: Union[str, List[str]], default: None
    image: ImageType, default: None
    mask_image: ImageType, default: None
    guidance_scale: float, default: 5.0
    guidance_rescale: float, default: 0.0
    num_inference_steps: int, default: 20
    num_images_per_prompt: int, default: 1
    height: int, default: None
    width: int, default: None
    timesteps: List[int], default: None
    sigmas: List[float], default: None
    denoising_end: float, default: None
    strength: float, default: None
    latents: torch.Tensor, default: None
    prompt_embeds: torch.Tensor, default: None
    negative_prompt_embeds: torch.Tensor, default: None
    pooled_prompt_embeds: torch.Tensor, default: None
    negative_pooled_prompt_embeds: torch.Tensor, default: None
    clip_skip: int, default: None
    seed: SeedType, default: None
    pag_scale: float, default: None
    pag_adaptive_scale: float, default: None
    scheduler: Literal[ddim, ddpm, ddpm_wuerstchen, deis_multistep, dpm_cogvideox, dpmsolver_multistep, dpmsolver_multistep_karras, dpmsolver_sde, dpmsolver_sde_multistep, dpmsolver_sde_multistep_karras, dpmsolver_singlestep, dpmsolver_singlestep_karras, edm_dpmsolver_multistep, edm_euler, euler_ancestral_discrete, euler_discrete, euler_discrete_karras, flow_match_euler_discrete, flow_match_heun_discrete, heun_discrete, ipndm, k_dpm_2_ancestral_discrete, k_dpm_2_ancestral_discrete_karras, k_dpm_2_discrete, k_dpm_2_discrete_karras, lcm, lms_discrete, lms_discrete_karras, pndm, tcd, unipc], default: None
    output_format: Literal[png, jpeg, float, int, latent], default: png
    output_upload: bool, default: False
    highres_fix_factor: float, default: 1.0
    highres_fix_strength: float, default: None
    spatial_prompts: SpatialPromptInputType, default: None
Returns:
    ImageResultType
```

## Invoking Tasks

### Direct Task Usage

```py
from taproot import Task
sdxl = Task.get("image-generation", "stable-diffusion-xl")
pipeline = sdxl()
pipeline.load()
pipeline(prompt="Hello, world!").save("./output.png")
```

### With a Remote Server

```py
from taproot import Tap
tap = Tap()
tap.remote_address = "ws://127.0.0.1:32189"
result = tap.call("image-generation", model="stable-diffusion-xl", prompt="Hello, world!")
result.save("./output.png")
```

### With a Local Server

Also shows asynchronous usage.

```py
import asyncio
from taproot import Tap
tap = Tap()
with tap.local() as tap:
    loop = asyncio.get_event_loop()
    result = loop.run_until_complete(tap("image-generation", model="stable-diffusion-xl", prompt="Hello, world!"))
    result.save("./output.png")
```

## Running Servers

Taproot uses a three-roled cluster structure:
1. **Overseers** are entry points into clusters, routing requests to one or more dispatchers.
2. **Dispatchers** are machines capable of executing tasks by spawning executors.
3. **Executors** are servers ready to execute a task.

The simplest way to run a server is to run an overseer simultaneously with a local dispatcher like so:

```sh
taproot overseer --local
```

This will run on the default address of `ws://127.0.0.1:32189`, suitable for interaction from python or the browser.

There are many deployment possibilities across networks, with configuration available for encryption, listening addresses, and more. See the wiki for details (coming soon.)

## Outside Python

- [taproot.js](https://github.com/painebenjamin/taproot.js) - for the browser and node.js, available in ESM, UMD and IIFE
- taproot.php - coming soon

<h1>Task Catalog</h1>
<p>17 tasks available with 144 models.</p>
<h2>echo</h2>
<table><tbody><tr><td>Name</td><td>Echo</td></tr><tr><td>Author</td><td>Benjamin Paine<br />Taproot<br />https://github.com/painebenjamin/taproot</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td>N/A</td></tr><tr><td>Minimum VRAM</td><td>N/A</td></tr></tbody></table>
<h2>image-similarity</h2>
<h3>(default)</h3>
<table><tbody><tr><td>Name</td><td>Traditional Image Similarity</td></tr><tr><td>Author</td><td>Benjamin Paine<br />Taproot<br />https://github.com/painebenjamin/taproot</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td>N/A</td></tr><tr><td>Minimum VRAM</td><td>N/A</td></tr></tbody></table>
<h3>inception-v3</h3>
<table><tbody><tr><td>Name</td><td>Inception Image Similarity (FID)</td></tr><tr><td>Author</td><td>Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jonathon Shlens and Zbigniew Wojna<br />Google Research and University College London<br />Published in CoRR, vol. 1512.00567, “Rethinking the Inception Architecture for Computer Vision”, 2015<br />https://arxiv.org/abs/1512.00567</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-similarity-inception.fp16.safetensors" target="_blank">image-similarity-inception.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>50.28 MB</td></tr></tbody></table>
<h2>text-similarity</h2>
<table><tbody><tr><td>Name</td><td>Traditional Text Similarity</td></tr><tr><td>Author</td><td>Benjamin Paine<br />Taproot<br />https://github.com/painebenjamin/taproot</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td>N/A</td></tr><tr><td>Minimum VRAM</td><td>N/A</td></tr></tbody></table>
<h2>speech-enhancement</h2>
<h3>deep-filter-net-v3 (default)</h3>
<table><tbody><tr><td>Name</td><td>DeepFilterNet V3 Speech Enhancement</td></tr><tr><td>Author</td><td>Hendrick Schröter, Tobias Rosenkranz, Alberto N. Escalante-B and Andreas Maier<br />Published in INTERSPEECH, “DeepFilterNet: Perceptually Motivated Real-Time Speech Enhancement”, 2023<br />https://arxiv.org/abs/2305.08227</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-enhancement-deep-filter-net-3.safetensors" target="_blank">speech-enhancement-deep-filter-net-3.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>87.89 MB</td></tr></tbody></table>
<h2>image-interpolation</h2>
<h3>film (default)</h3>
<table><tbody><tr><td>Name</td><td>Frame Interpolation for Large Motion (FiLM) Image Interpolation</td></tr><tr><td>Author</td><td>Fitsum Reda, Janne Jontkanen, Eric Tabellion, Deqing Sun, Caroline Pantofaru and Brian Curless<br />Google Research and University of Washington<br />Published in ECCV, “FiLM: Frame Interpolation for Large Motion”, 2022<br />https://arxiv.org/abs/2202.04901</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://github.com/dajes/frame-interpolation-pytorch/releases/download/v1.0.2/film_net_fp16.pt?filename=image-interpolation-film-net.fp16.pt" target="_blank">image-interpolation-film-net.fp16.pt</a></td></tr><tr><td>Minimum VRAM</td><td>70.00 MB</td></tr></tbody></table>
<h3>rife</h3>
<table><tbody><tr><td>Name</td><td>Real-Time Intermediate Flow Estimation (RIFE) Image Interpolation</td></tr><tr><td>Author</td><td>Zhewei Huang, Tianyuan Zhang, Wen Heng, Boxin Shi and Shuchang Zhou<br />Megvii Research, NERCVT, School of Computer Science, Peking University, Institute for Artificial Intelligence, Peking University and Beijing Academy of Artificial Intelligence<br />Published in ECCV, “Real-Time Intermediate Flow Estimation for Video Frame Interpolation”, 2022<br />https://arxiv.org/abs/2011.06294</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://github.com/dajes/frame-interpolation-pytorch/releases/download/v1.0.2/film_net_fp16.pt?filename=image-interpolation-rife-flownet.safetensors" target="_blank">image-interpolation-rife-flownet.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>25.00 MB</td></tr></tbody></table>
<h2>background-removal</h2>
<h3>backgroundremover (default)</h3>
<table><tbody><tr><td>Name</td><td>BackgroundRemover</td></tr><tr><td>Author</td><td>Johnathan Nader, Lucas Nestler, Dr. Tim Scarfe and Daniel Gatis<br />https://github.com/nadermx/backgroundremover</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/background-removal-u2net.safetensors" target="_blank">background-removal-u2net.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>217.62 MB</td></tr></tbody></table>
<h2>super-resolution</h2>
<h3>aura</h3>
<table><tbody><tr><td>Name</td><td>Aura Super Resolution</td></tr><tr><td>Author</td><td>fal.ai<br />Published in fal.ai blog, “Introducing AuraSR - An open reproduction of the GigaGAN Upscaler”, 2024<br />https://blog.fal.ai/introducing-aurasr-an-open-reproduction-of-the-gigagan-upscaler-2/</td></tr><tr><td>License</td><td>CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/super-resolution-aura.fp16.safetensors" target="_blank">super-resolution-aura.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>1.24 GB</td></tr></tbody></table>
<h3>aura-v2 (default)</h3>
<table><tbody><tr><td>Name</td><td>Aura Super Resolution V2</td></tr><tr><td>Author</td><td>fal.ai<br />Published in fal.ai blog, “AuraSR V2”, 2024<br />https://blog.fal.ai/aurasr-v2/</td></tr><tr><td>License</td><td>CC BY-SA 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/super-resolution-aura-v2.fp16.safetensors" target="_blank">super-resolution-aura-v2.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>1.24 GB</td></tr></tbody></table>
<h2>speech-synthesis</h2>
<h3>xtts-v2 (default)</h3>
<table><tbody><tr><td>Name</td><td>XTTS2 Speech Synthesis</td></tr><tr><td>Author</td><td>Coqui AI<br />Published in Coqui AI Blog, “XTTS: Open Model Release Announcement”, 2023<br />https://coqui.ai/blog/tts/open_xtts</td></tr><tr><td>License</td><td>Mozilla Public License 2.0 (https://www.mozilla.org/en-US/MPL/2.0/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-synthesis-xtts-v2.safetensors" target="_blank">speech-synthesis-xtts-v2.safetensors (1.87 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-synthesis-xtts-v2-speakers.pth" target="_blank">speech-synthesis-xtts-v2-speakers.pth (7.75 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-synthesis-xtts-v2-vocab.json" target="_blank">speech-synthesis-xtts-v2-vocab.json (361.22 KB)</a></li></ol><p><strong>Total Size</strong>: 1.88 GB</p></td></tr><tr><td>Minimum VRAM</td><td>1.91 GB</td></tr></tbody></table>
<h3>f5tts</h3>
<table><tbody><tr><td>Name</td><td>F5TTS Speech Synthesis</td></tr><tr><td>Author</td><td>Yushen Chen, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, Jian Zhao, Kai Yu and Xie Chen<br />Published in arXiv, vol. 2410.06885, “F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching”, 2024<br />https://arxiv.org/abs/2410.06885</td></tr><tr><td>License</td><td>CC BY-NC 4.0 (https://creativecommons.org/licenses/by-nc/4.0/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-synthesis-f5tts.safetensors" target="_blank">speech-synthesis-f5tts.safetensors (1.35 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/speech-synthesis-f5tts-vocab.txt" target="_blank">speech-synthesis-f5tts-vocab.txt (11.26 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/audio-vocoder-vocos-mel-24khz.safetensors" target="_blank">audio-vocoder-vocos-mel-24khz.safetensors (54.35 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/audio-vocoder-vocos-mel-24khz-config.yaml" target="_blank">audio-vocoder-vocos-mel-24khz-config.yaml (461.00 B)</a></li></ol><p><strong>Total Size</strong>: 1.40 GB</p></td></tr><tr><td>Minimum VRAM</td><td>3.94 GB</td></tr></tbody></table>
<h2>audio-transcription</h2>
<h3>whisper-tiny</h3>
<table><tbody><tr><td>Name</td><td>Whisper Tiny Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-tiny/resolve/main/model.safetensors?filename=audio-transcription-whisper-tiny.safetensors" target="_blank">audio-transcription-whisper-tiny.safetensors (151.06 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-vocab.json (835.55 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer.json" target="_blank">audio-transcription-whisper-tokenizer.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 154.92 MB</p></td></tr><tr><td>Minimum VRAM</td><td>147.85 MB</td></tr></tbody></table>
<h3>whisper-base</h3>
<table><tbody><tr><td>Name</td><td>Whisper Base Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-base/resolve/main/model.safetensors?filename=audio-transcription-whisper-base.safetensors" target="_blank">audio-transcription-whisper-base.safetensors (290.40 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-vocab.json (835.55 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer.json" target="_blank">audio-transcription-whisper-tokenizer.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 294.27 MB</p></td></tr><tr><td>Minimum VRAM</td><td>285.74 MB</td></tr></tbody></table>
<h3>whisper-small</h3>
<table><tbody><tr><td>Name</td><td>Whisper Small Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-small/resolve/main/model.safetensors?filename=audio-transcription-whisper-small.safetensors" target="_blank">audio-transcription-whisper-small.safetensors (967.00 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-vocab.json (835.55 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer.json" target="_blank">audio-transcription-whisper-tokenizer.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 970.86 MB</p></td></tr><tr><td>Minimum VRAM</td><td>945.03 MB</td></tr></tbody></table>
<h3>whisper-medium</h3>
<table><tbody><tr><td>Name</td><td>Whisper Medium Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-medium/resolve/main/model.safetensors?filename=audio-transcription-whisper-medium.safetensors" target="_blank">audio-transcription-whisper-medium.safetensors (3.06 GB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-vocab.json (835.55 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-base/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer.json" target="_blank">audio-transcription-whisper-tokenizer.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 3.06 GB</p></td></tr><tr><td>Minimum VRAM</td><td>3.06 GB</td></tr></tbody></table>
<h3>whisper-large-v3</h3>
<table><tbody><tr><td>Name</td><td>Whisper Large V3 Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-large-v3/resolve/main/model.safetensors?filename=audio-transcription-whisper-large-v3.fp16.safetensors" target="_blank">audio-transcription-whisper-large-v3.fp16.safetensors (3.09 GB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-v3-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-v3-vocab.json (1.04 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-v3-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-v3-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-v3-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-v3-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer-v3.json" target="_blank">audio-transcription-whisper-tokenizer-v3.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 3.09 GB</p></td></tr><tr><td>Minimum VRAM</td><td>3.09 GB</td></tr></tbody></table>
<h3>distilled-whisper-small-english</h3>
<table><tbody><tr><td>Name</td><td>Distilled Whisper Small (English) Audio Transcription</td></tr><tr><td>Author</td><td>Sanchit Gandhi, Patrick von Platen and Alexander M. Rush<br />Hugging Face<br />Published in arXiv, vol. 2311.00430, “Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling”, 2023<br />https://arxiv.org/abs/2311.00430</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/distil-whisper/distil-small.en/resolve/main/model.safetensors?filename=audio-transcription-distilled-whisper-small-english.safetensors" target="_blank">audio-transcription-distilled-whisper-small-english.safetensors (332.30 MB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/vocab.json?filename=audio-transcription-distilled-whisper-english-tokenizer-vocab.json" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-vocab.json (999.19 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/merges.txt?filename=audio-transcription-distilled-whisper-english-tokenizer-merges.txt" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-merges.txt (456.32 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/normalizer.json?filename=audio-transcription-distilled-whisper-english-tokenizer-normalizer.json" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/tokenizer.json?filename=audio-transcription-distillled-whisper-english-tokenizer.json" target="_blank">audio-transcription-distillled-whisper-english-tokenizer.json (2.41 MB)</a></li></ol><p><strong>Total Size</strong>: 336.21 MB</p></td></tr><tr><td>Minimum VRAM</td><td>649.01 MB</td></tr></tbody></table>
<h3>distilled-whisper-medium-english</h3>
<table><tbody><tr><td>Name</td><td>Distilled Whisper Medium (English) Audio Transcription</td></tr><tr><td>Author</td><td>Sanchit Gandhi, Patrick von Platen and Alexander M. Rush<br />Hugging Face<br />Published in arXiv, vol. 2311.00430, “Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling”, 2023<br />https://arxiv.org/abs/2311.00430</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/distil-whisper/distil-medium.en/resolve/main/model.safetensors?filename=audio-transcription-distilled-whisper-medium-english.safetensors" target="_blank">audio-transcription-distilled-whisper-medium-english.safetensors (788.80 MB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/vocab.json?filename=audio-transcription-distilled-whisper-english-tokenizer-vocab.json" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-vocab.json (999.19 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/merges.txt?filename=audio-transcription-distilled-whisper-english-tokenizer-merges.txt" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-merges.txt (456.32 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/normalizer.json?filename=audio-transcription-distilled-whisper-english-tokenizer-normalizer.json" target="_blank">audio-transcription-distilled-whisper-english-tokenizer-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/distil-whisper/distil-small.en/raw/main/tokenizer.json?filename=audio-transcription-distillled-whisper-english-tokenizer.json" target="_blank">audio-transcription-distillled-whisper-english-tokenizer.json (2.41 MB)</a></li></ol><p><strong>Total Size</strong>: 792.71 MB</p></td></tr><tr><td>Minimum VRAM</td><td>1.58 GB</td></tr></tbody></table>
<h3>distilled-whisper-large-v3 (default)</h3>
<table><tbody><tr><td>Name</td><td>Distilled Whisper Large V3 Audio Transcription</td></tr><tr><td>Author</td><td>Sanchit Gandhi, Patrick von Platen and Alexander M. Rush<br />Hugging Face<br />Published in arXiv, vol. 2311.00430, “Distil-Whisper: Robust Knowledge Distillation via Large-Scale Pseudo Labelling”, 2023<br />https://arxiv.org/abs/2311.00430</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/distil-whisper/distil-large-v3/resolve/main/model.safetensors?filename=audio-transcription-distilled-whisper-large-v3.fp16.safetensors" target="_blank">audio-transcription-distilled-whisper-large-v3.fp16.safetensors (1.51 GB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-v3-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-v3-vocab.json (1.04 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-v3-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-v3-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-v3-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-v3-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer-v3.json" target="_blank">audio-transcription-whisper-tokenizer-v3.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 1.52 GB</p></td></tr><tr><td>Minimum VRAM</td><td>1.51 GB</td></tr></tbody></table>
<h3>turbo-whisper-large-v3</h3>
<table><tbody><tr><td>Name</td><td>Turbo Whisper Large V3 Audio Transcription</td></tr><tr><td>Author</td><td>Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey and Ilya Sutskever<br />OpenAI<br />Published in arXiv, vol. 2212.04356, “Robust Speech Recognition via Large-Scale Weak Supervision”<br />https://arxiv.org/abs/2212.04356</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/openai/whisper-large-v3-turbo/resolve/main/model.safetensors?filename=audio-transcription-whisper-large-v3-turbo.fp16.safetensors" target="_blank">audio-transcription-whisper-large-v3-turbo.fp16.safetensors (1.62 GB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/vocab.json?filename=audio-transcription-whisper-tokenizer-v3-vocab.json" target="_blank">audio-transcription-whisper-tokenizer-v3-vocab.json (1.04 MB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/merges.txt?filename=audio-transcription-whisper-tokenizer-v3-merges.txt" target="_blank">audio-transcription-whisper-tokenizer-v3-merges.txt (493.87 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/normalizer.json?filename=audio-transcription-whisper-tokenizer-v3-normalizer.json" target="_blank">audio-transcription-whisper-tokenizer-v3-normalizer.json (52.67 KB)</a></li><li><a href="https://huggingface.co/openai/whisper-large-v3/raw/main/tokenizer.json?filename=audio-transcription-whisper-tokenizer-v3.json" target="_blank">audio-transcription-whisper-tokenizer-v3.json (2.48 MB)</a></li></ol><p><strong>Total Size</strong>: 1.62 GB</p></td></tr><tr><td>Minimum VRAM</td><td>1.62 GB</td></tr></tbody></table>
<h2>depth-detection</h2>
<h3>midas (default)</h3>
<table><tbody><tr><td>Name</td><td>MiDaS Depth Detection</td></tr><tr><td>Author</td><td>René Ranftl, Alexey Bochkovskiy and Vladlen Koltun<br />Published in arXiv, vol. 2103.13413, “Vision Transformers for Dense Prediction”, 2021<br />https://arxiv.org/abs/2103.13413</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/depth-detection-midas.fp16.safetensors" target="_blank">depth-detection-midas.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>255.65 MB</td></tr></tbody></table>
<h2>line-detection</h2>
<h3>informative-drawings (default)</h3>
<table><tbody><tr><td>Name</td><td>Informative Drawings Line Art Detection</td></tr><tr><td>Author</td><td>Caroline Chan, Fredo Durand and Phillip Isola<br />Massachusetts Institute of Technology<br />Published in arXiv, vol. 2203.12691, “Informative Drawings: Learning to Generate Line Drawings that Convey Geometry and Semantics”, 2022<br />https://arxiv.org/abs/2203.12691</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/line-detection-sk.fp16.safetensors" target="_blank">line-detection-sk.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>8.58 MB</td></tr></tbody></table>
<h3>informative-drawings-coarse</h3>
<table><tbody><tr><td>Name</td><td>Informative Drawings Coarse Line Art Detection</td></tr><tr><td>Author</td><td>Caroline Chan, Fredo Durand and Phillip Isola<br />Massachusetts Institute of Technology<br />Published in arXiv, vol. 2203.12691, “Informative Drawings: Learning to Generate Line Drawings that Convey Geometry and Semantics”, 2022<br />https://arxiv.org/abs/2203.12691</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/line-detection-sk-coarse.fp16.safetensors" target="_blank">line-detection-sk-coarse.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>8.58 MB</td></tr></tbody></table>
<h3>informative-drawings-anime</h3>
<table><tbody><tr><td>Name</td><td>Informative Drawings Anime Line Art Detection</td></tr><tr><td>Author</td><td>Caroline Chan, Fredo Durand and Phillip Isola<br />Massachusetts Institute of Technology<br />Published in arXiv, vol. 2203.12691, “Informative Drawings: Learning to Generate Line Drawings that Convey Geometry and Semantics”, 2022<br />https://arxiv.org/abs/2203.12691</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/line-detection-anime.fp16.safetensors" target="_blank">line-detection-anime.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>108.81 MB</td></tr></tbody></table>
<h3>mlsd</h3>
<table><tbody><tr><td>Name</td><td>Mobile Line Segment Detection</td></tr><tr><td>Author</td><td>Geonmo Gu, Byungsoo Ko, SeongHyun Go, Sung-Hyun Lee, Jingeun Lee and Minchul Shin<br />NAVER/LINE Vision<br />Published in arXiv, vol. 2106.00186, “Towards Light-weight and Real-time Line Segment Detection”, 2022<br />https://arxiv.org/abs/2106.00186</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/line-detection-mlsd.fp16.safetensors" target="_blank">line-detection-mlsd.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>3.22 MB</td></tr></tbody></table>
<h2>edge-detection</h2>
<h3>canny (default)</h3>
<table><tbody><tr><td>Name</td><td>Canny Edge Detection</td></tr><tr><td>Author</td><td>John Canny<br />Published in IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 6, pp. 679-698, “A Computational Approach to Edge Detection”, 1986<br />https://ieeexplore.ieee.org/document/4767851<br />Implementation by OpenCV (https://opencv.org/)</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td>N/A</td></tr><tr><td>Minimum VRAM</td><td>N/A</td></tr></tbody></table>
<h3>hed</h3>
<table><tbody><tr><td>Name</td><td>Holistically-Nested Edge Detection</td></tr><tr><td>Author</td><td>Saining Xieand Zhuowen Tu<br />University of California, San Diego<br />Published in arXiv, vol. 1504.06375, “Holistically-Nested Edge Detection”, 2015<br />https://arxiv.org/abs/1504.06375</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/edge-detection-hed.fp16.safetensors" target="_blank">edge-detection-hed.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>29.44 MB</td></tr></tbody></table>
<h3>pidi</h3>
<table><tbody><tr><td>Name</td><td>Soft Edge (PIDI) Detection</td></tr><tr><td>Author</td><td>Zhuo Su, Wenzhe Liu, Zitong Yu, Dewen Hu, Qing Liao, Qi Tian, Matti Pietikäinen and Li Liu<br />Published in Proceedings of the IEEE/CVF International Conference on Computer Vision, pp. 5117-5127, “Pixel Difference Networks for Efficient Edge Detection”, 2021</td></tr><tr><td>License</td><td>MIT License with Non-Commercial Clause (https://github.com/hellozhuo/pidinet/blob/master/LICENSE)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/edge-detection-pidi.fp16.safetensors" target="_blank">edge-detection-pidi.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>1.40 MB</td></tr></tbody></table>
<h2>pose-detection</h2>
<h3>openpose</h3>
<table><tbody><tr><td>Name</td><td>OpenPose Pose Detection</td></tr><tr><td>Author</td><td>Zhe Cao, Gines Hidalgo, Tomas Simon, Shih-En Wei and Yaser Sheikh<br />Published in arXiv, vol. 1812.08008, “OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields”, 2018<br />https://arxiv.org/abs/1812.08008</td></tr><tr><td>License</td><td>OpenPose Academic or Non-Profit Non-Commercial Research License (https://github.com/CMU-Perceptual-Computing-Lab/openpose/blob/master/LICENSE)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/pose-detection-openpose.fp16.safetensors" target="_blank">pose-detection-openpose.fp16.safetensors</a></td></tr><tr><td>Minimum VRAM</td><td>259.96 MB</td></tr></tbody></table>
<h3>dwpose (default)</h3>
<table><tbody><tr><td>Name</td><td>DWPose Pose Detection</td></tr><tr><td>Author</td><td>Zhengdong Yang, Ailing Zeng, Chun Yuan and Yu Li<br />Tsinghua Zhenzhen International Graduate School and International Digital Economy Academy (IDEA)<br />Published in arXiv, vol. 2307.15880, “Effective Whole-body Pose Estimation with Two-stages Distillation”, 2023<br />https://arxiv.org/abs/2307.15880</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/pose-detection-dwpose-estimation.safetensors" target="_blank">pose-detection-dwpose-estimation.safetensors (134.65 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/pose-detection-dwpose-detection.safetensors" target="_blank">pose-detection-dwpose-detection.safetensors (217.20 MB)</a></li></ol><p><strong>Total Size</strong>: 351.85 MB</p></td></tr><tr><td>Minimum VRAM</td><td>354.64 MB</td></tr></tbody></table>
<h2>image-generation</h2>
<h3>stable-diffusion-v1-5</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion v1.5 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752</td></tr><tr><td>License</td><td>OpenRAIL-M License (https://bigscience.huggingface.co/blog/bigscience-openrail-m)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/stable-diffusion-v1-5/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-abyssorange-mix-v3</h3>
<table><tbody><tr><td>Name</td><td>AbyssOrange Mix V3 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by liudinglin (https://civitai.com/user/liudinglin)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/17233)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-abyssorange-mix-v3-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-abyssorange-mix-v3-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-abyssorange-mix-v3-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-abyssorange-mix-v3-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-chillout-mix-ni</h3>
<table><tbody><tr><td>Name</td><td>Chillout Mix Ni Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Dreamlike Art (https://dreamlike.art)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://huggingface.co/dreamlike-art/dreamlike-diffusion-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-chillout-mix-ni-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-chillout-mix-ni-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-chillout-mix-ni-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-chillout-mix-ni-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-clarity-v3</h3>
<table><tbody><tr><td>Name</td><td>Clarity V3 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by ndimensional (https://civitai.com/user/ndimensional)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/142125)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-clarity-v3-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-clarity-v3-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-clarity-v3-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-clarity-v3-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-dark-sushi-mix-v2-25d</h3>
<table><tbody><tr><td>Name</td><td>Dark Sushi Mix V2 2.5D Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Aitasai (https://civitai.com/user/Aitasai)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/93208)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-dark-sushi-mix-v2-25d-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-dark-sushi-mix-v2-25d-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-dark-sushi-mix-v2-25d-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-dark-sushi-mix-v2-25d-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-divine-elegance-mix-v10</h3>
<table><tbody><tr><td>Name</td><td>Divine Elegance Mix V10 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by TroubleDarkness (https://civitai.com/user/TroubleDarkness)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/432048)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-divine-elegance-mix-v10-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-divine-elegance-mix-v10-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-divine-elegance-mix-v10-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-divine-elegance-mix-v10-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-dreamshaper-v8</h3>
<table><tbody><tr><td>Name</td><td>DreamShaper V8 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Lykon (https://civitai.com/user/Lykon)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/128713)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-dreamshaper-v8-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-dreamshaper-v8-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-dreamshaper-v8-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-dreamshaper-v8-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-epicrealism-v5</h3>
<table><tbody><tr><td>Name</td><td>epiCRealism V5 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by epinikion (https://civitai.com/user/epinikion)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/143906)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-epicrealism-v5-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-epicrealism-v5-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-epicrealism-v5-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-epicrealism-v5-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-epicphotogasm-ultimate-fidelity</h3>
<table><tbody><tr><td>Name</td><td>epiCPhotoGasm Ultimate Fidelity Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by epinikion (https://civitai.com/user/epinikion)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/429454)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-epic-photogasm-ultimate-fidelity-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-epic-photogasm-ultimate-fidelity-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-epic-photogasm-ultimate-fidelity-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-epic-photogasm-ultimate-fidelity-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-ghostmix-v2</h3>
<table><tbody><tr><td>Name</td><td>GhostMix V2 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by _GhostInShell_ (https://civitai.com/user/_GhostInShell_)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/76907)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-ghostmix-v2-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-ghostmix-v2-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-ghostmix-v2-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-ghostmix-v2-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-lyriel-v1-6</h3>
<table><tbody><tr><td>Name</td><td>Lyriel V1.6 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Lyriel (https://civitai.com/user/Lyriel)</td></tr><tr><td>License</td><td>OpenRAIL-M License (https://civitai.com/models/license/72396)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-lyriel-v1-6-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-lyriel-v1-6-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-lyriel-v1-6-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-lyriel-v1-6-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-majicmix-realistic-v7</h3>
<table><tbody><tr><td>Name</td><td>MajicMix Realistic V7 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Merjic (https://civitai.com/user/Merjic)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/176425)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-majicmix-realistic-v7-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-majicmix-realistic-v7-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-majicmix-realistic-v7-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-majicmix-realistic-v7-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-meinamix-v12</h3>
<table><tbody><tr><td>Name</td><td>MeinaMix V12 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Meina (https://civitai.com/user/Meina)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/948574)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-meinamix-v12-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-meinamix-v12-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-meinamix-v12-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-meinamix-v12-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-mistoon-anime-v3</h3>
<table><tbody><tr><td>Name</td><td>Mistoon Anime V3 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Inzaniak (https://civitai.com/user/Inzaniak)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/348981)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-mistoon-anime-v3-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-mistoon-anime-v3-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-mistoon-anime-v3-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-mistoon-anime-v3-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-perfect-world-v6</h3>
<table><tbody><tr><td>Name</td><td>Perfect World V6 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Bloodsuga (https://civitai.com/user/Bloodsuga)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/179446)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-perfect-world-v6-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-perfect-world-v6-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-perfect-world-v6-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-perfect-world-v6-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-photon-v1</h3>
<table><tbody><tr><td>Name</td><td>Photon V1 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Photographer (https://civitai.com/user/Photographer)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/900072)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-photon-v1-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-photon-v1-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-photon-v1-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-photon-v1-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-realcartoon3d-v17</h3>
<table><tbody><tr><td>Name</td><td>RealCartoon3D V17 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by 7whitefire7 (https://civitai.com/user/7whitefire7)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/637156)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realcartoon3d-v17-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realcartoon3d-v17-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realcartoon3d-v17-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realcartoon3d-v17-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-realistic-vision-v5-1</h3>
<table><tbody><tr><td>Name</td><td>Realistic Vision V5.1 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by SG_161222 (https://civitai.com/user/SG_161222)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/130072)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realistic-vision-v5-1-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realistic-vision-v5-1-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realistic-vision-v5-1-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realistic-vision-v5-1-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-realistic-vision-v6-0</h3>
<table><tbody><tr><td>Name</td><td>Realistic Vision V6.0 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by SG_161222 (https://civitai.com/user/SG_161222)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/245592)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realistic-vision-v6-0-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realistic-vision-v6-0-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-realistic-vision-v6-0-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-realistic-vision-v6-0-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-rev-animated-v2</h3>
<table><tbody><tr><td>Name</td><td>ReV Animated V2 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Zovya (https://civitai.com/user/Zovya)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/425083)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-rev-animated-v2-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-rev-animated-v2-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-rev-animated-v2-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-rev-animated-v2-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-v1-5-toonyou-beta-v6</h3>
<table><tbody><tr><td>Name</td><td>ToonYou Beta V6 Image Generation</td></tr><tr><td>Author</td><td>Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser and Björn Ommer<br />Published in Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pp. 10684-10695, “High-Resolution Image Synthesis With Latent Diffusion Models”, 2022<br />https://arxiv.org/abs/2112.10752<br />Finetuned by Bradcatt (https://civitai.com/user/Bradcatt)</td></tr><tr><td>License</td><td>OpenRAIL-M License with Restrictions (https://civitai.com/models/license/125771)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/vae/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v1-5-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-vae.fp16.safetensors (167.34 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-toonyou-beta-v6-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-toonyou-beta-v6-unet.fp16.safetensors (1.72 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-v1-5-toonyou-beta-v6-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v1-5-toonyou-beta-v6-text-encoder.fp16.safetensors (246.14 MB)</a></li></ol><p><strong>Total Size</strong>: 2.13 GB</p></td></tr><tr><td>Minimum VRAM</td><td>2.58 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion XL Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-xl-base-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-albedobase-v3-1</h3>
<table><tbody><tr><td>Name</td><td>AlbedoBase XL V3.1 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/1041855)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-albedo-base-v3-1-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-albedo-base-v3-1-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-albedo-base-v3-1-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-albedo-base-v3-1-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-albedo-base-v3-1-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-albedo-base-v3-1-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-anything</h3>
<table><tbody><tr><td>Name</td><td>Anything XL Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-anything-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-anything-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-anything-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-anything-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-anything-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-anything-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-animagine-v3-1</h3>
<table><tbody><tr><td>Name</td><td>Animagine XL V3.1 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/403131)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-animagine-v3-1-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-animagine-v3-1-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-animagine-v3-1-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-animagine-v3-1-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-animagine-v3-1-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-animagine-v3-1-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-copax-timeless-v13</h3>
<table><tbody><tr><td>Name</td><td>Copax TimeLess V13 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/724334)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-copax-timeless-v13-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-copax-timeless-v13-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-copax-timeless-v13-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-copax-timeless-v13-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-copax-timeless-v13-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-copax-timeless-v13-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-counterfeit-v2-5</h3>
<table><tbody><tr><td>Name</td><td>CounterfeitXL V2.5 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/265012)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-counterfeit-v2-5-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-counterfeit-v2-5-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-counterfeit-v2-5-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-counterfeit-v2-5-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-counterfeit-v2-5-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-counterfeit-v2-5-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-dreamshaper-alpha-v2</h3>
<table><tbody><tr><td>Name</td><td>DreamShaper XL Alpha V2 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/126688)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-dreamshaper-alpha-v2-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-helloworld-v7</h3>
<table><tbody><tr><td>Name</td><td>LEOSAM's HelloWorld XL Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/570138)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-hello-world-v7-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-hello-world-v7-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-hello-world-v7-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-hello-world-v7-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-hello-world-v7-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-hello-world-v7-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-juggernaut-v11 (default)</h3>
<table><tbody><tr><td>Name</td><td>Juggernaut XL V11 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/782002)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-juggernaut-v11-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-juggernaut-v11-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-juggernaut-v11-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-juggernaut-v11-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-juggernaut-v11-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-juggernaut-v11-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-lightning-8-step</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion XL Lightning (8-Step)</td></tr><tr><td>Author</td><td>Shanchuan Lin, Anran Wang and Xiao Yang<br />ByteDance Inc.<br />Published in arXiv, vol. 2402.13929, “SDXL-Lightning: PRogressive Adversarial Diffusion Distillation”, 2024<br />https://arxiv.org/abs/2402.13929</td></tr><tr><td>License</td><td>OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_8step_unet.safetensors?filename=image-generation-stable-diffusion-xl-lightning-unet-8-step.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-lightning-unet-8-step.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-lightning-4-step</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion XL Lightning (4-Step)</td></tr><tr><td>Author</td><td>Shanchuan Lin, Anran Wang and Xiao Yang<br />ByteDance Inc.<br />Published in arXiv, vol. 2402.13929, “SDXL-Lightning: PRogressive Adversarial Diffusion Distillation”, 2024<br />https://arxiv.org/abs/2402.13929</td></tr><tr><td>License</td><td>OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_4step_unet.safetensors?filename=image-generation-stable-diffusion-xl-lightning-unet-4-step.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-lightning-unet-4-step.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-lightning-2-step</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion XL Lightning (2-Step)</td></tr><tr><td>Author</td><td>Shanchuan Lin, Anran Wang and Xiao Yang<br />ByteDance Inc.<br />Published in arXiv, vol. 2402.13929, “SDXL-Lightning: PRogressive Adversarial Diffusion Distillation”, 2024<br />https://arxiv.org/abs/2402.13929</td></tr><tr><td>License</td><td>OpenRAIL++-M License (https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/ByteDance/SDXL-Lightning/resolve/main/sdxl_lightning_2step_unet.safetensors?filename=image-generation-stable-diffusion-xl-lightning-unet-2-step.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-lightning-unet-2-step.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-nightvision-v9</h3>
<table><tbody><tr><td>Name</td><td>NightVision XL V9 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/577919)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-nightvision-v9-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-nightvision-v9-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-nightvision-v9-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-nightvision-v9-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-nightvision-v9-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-nightvision-v9-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-realvis-v5</h3>
<table><tbody><tr><td>Name</td><td>RealVisXL V5 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/789646)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-realvis-v5-0-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-realvis-v5-0-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-realvis-v5-0-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-realvis-v5-0-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-realvis-v5-0-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-realvis-v5-0-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-stoiqo-newreality-pro</h3>
<table><tbody><tr><td>Name</td><td>Stoiqo New Reality XL Pro Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/690310)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-stoiqo-newreality-pro-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-stoiqo-newreality-pro-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-stoiqo-newreality-pro-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-stoiqo-newreality-pro-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-stoiqo-newreality-pro-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-stoiqo-newreality-pro-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-turbo</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion XL Turbo Image Generation</td></tr><tr><td>Author</td><td>Axel Sauer, Dominik Lorenz, Andreas Blattmann and Robin Rombach<br />Stability AI<br />Published in Stability AI Blog, vol. 2307.01952, “Adversarial Diffusion Distillation”, 2024<br />https://stability.ai/research/adversarial-diffusion-distillation</td></tr><tr><td>License</td><td>Stability AI Community License (https://huggingface.co/stabilityai/sdxl-turbo/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/stabilityai/sdxl-turbo/resolve/main/unet/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-xl-turbo-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-turbo-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-unstable-diffusers-nihilmania</h3>
<table><tbody><tr><td>Name</td><td>SDXL Unstable Diffusers NihilMania Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/395107)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-unstable-diffusers-nihilmania-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-xl-zavychroma-v10</h3>
<table><tbody><tr><td>Name</td><td>ZavyChromaXL V10 Image Generation</td></tr><tr><td>Author</td><td>Dustin Podell, Zion English, Kyle Lacey, Andreas Blattmann, Tim Dockhorn, Jonas Müller, Joe Penna and Robin Rombach<br />Published in arXiv, vol. 2307.01952, “SDXL: Improving Latent Diffusion Models for High-Resolution Image Synthesis”, 2023<br />https://arxiv.org/abs/2307.01952</td></tr><tr><td>License</td><td>OpenRAIL++-M License with Restrictions (https://civitai.com/models/license/916744)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/madebyollin/sdxl-vae-fp16-fix/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-xl-base-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-base-vae.fp16.safetensors (334.64 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-zavychroma-v10-unet.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-zavychroma-v10-unet.fp16.safetensors (5.14 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-zavychroma-v10-text-encoder.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-zavychroma-v10-text-encoder.fp16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-stable-diffusion-xl-zavychroma-v10-text-encoder-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-xl-zavychroma-v10-text-encoder-2.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li></ol><p><strong>Total Size</strong>: 7.11 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.06 GB</td></tr></tbody></table>
<h3>stable-diffusion-v3-medium</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion V3 (Medium) Image Generation</td></tr><tr><td>Author</td><td>Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek and Robin Rombach<br />Stability AI<br />Published in arXiv, vol. 2403.03206, “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis”, 2024<br />https://arxiv.org/abs/2403.03206</td></tr><tr><td>License</td><td>Stability AI Community License Agreement (https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/transformer/diffusion_pytorch_model.fp16.safetensors?filename=image-generation-stable-diffusion-v3-transformer.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-transformer.fp16.safetensors (4.17 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.fp16.safetensors" target="_blank">text-encoding-t5-xxl.fp16.safetensors (9.52 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li></ol><p><strong>Total Size</strong>: 15.50 GB</p></td></tr><tr><td>Minimum VRAM</td><td>17.86 GB</td></tr></tbody></table>
<h3>stable-diffusion-v3-5-medium</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion V3.5 (Medium) Image Generation</td></tr><tr><td>Author</td><td>Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek and Robin Rombach<br />Stability AI<br />Published in arXiv, vol. 2403.03206, “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis”, 2024<br />https://arxiv.org/abs/2403.03206</td></tr><tr><td>License</td><td>Stability AI Community License Agreement (https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-medium/resolve/main/transformer/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-5-medium-transformer.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-5-medium-transformer.fp16.safetensors (4.94 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.fp16.safetensors" target="_blank">text-encoding-t5-xxl.fp16.safetensors (9.52 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li></ol><p><strong>Total Size</strong>: 16.27 GB</p></td></tr><tr><td>Minimum VRAM</td><td>18.36 GB</td></tr></tbody></table>
<h3>stable-diffusion-v3-5-large</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion V3.5 (Large) Image Generation</td></tr><tr><td>Author</td><td>Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek and Robin Rombach<br />Stability AI<br />Published in arXiv, vol. 2403.03206, “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis”, 2024<br />https://arxiv.org/abs/2403.03206</td></tr><tr><td>License</td><td>Stability AI Community License Agreement (https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/transformer/diffusion_pytorch_model-00001-of-00002.safetensors?filename=image-generation-stable-diffusion-v3-5-large-transformer.part-1.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-5-large-transformer.part-1.fp16.safetensors (9.99 GB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/transformer/diffusion_pytorch_model-00002-of-00002.safetensors?filename=image-generation-stable-diffusion-v3-5-large-transformer.part-2.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-5-large-transformer.part-2.fp16.safetensors (6.31 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.fp16.safetensors" target="_blank">text-encoding-t5-xxl.fp16.safetensors (9.52 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li></ol><p><strong>Total Size</strong>: 27.62 GB</p></td></tr><tr><td>Minimum VRAM</td><td>31.36 GB</td></tr></tbody></table>
<h3>stable-diffusion-v3-5-large-8bit</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion V3.5 (Large) Image Generation (8-Bit)</td></tr><tr><td>Author</td><td>Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek and Robin Rombach<br />Stability AI<br />Published in arXiv, vol. 2403.03206, “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis”, 2024<br />https://arxiv.org/abs/2403.03206</td></tr><tr><td>License</td><td>Stability AI Community License Agreement (https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/transformer/diffusion_pytorch_model-00002-of-00002.safetensors?filename=image-generation-stable-diffusion-v3-5-large-transformer.8bit.bf16.safetensors" target="_blank">image-generation-stable-diffusion-v3-5-large-transformer.8bit.bf16.safetensors (6.31 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.nf4.fp16.safetensors" target="_blank">text-encoding-t5-xxl.nf4.fp16.safetensors (6.33 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li></ol><p><strong>Total Size</strong>: 14.44 GB</p></td></tr><tr><td>Minimum VRAM</td><td>16.85 GB</td></tr></tbody></table>
<h3>stable-diffusion-v3-5-large-nf4</h3>
<table><tbody><tr><td>Name</td><td>Stable Diffusion 3.5 (Large) Image Generation (NF4)</td></tr><tr><td>Author</td><td>Patrick Esser, Sumith Kulal, Andreas Blattmann, Rahim Entezari, Jonas Müller, Harry Saini, Yam Levi, Dominik Lorenz, Axel Sauer, Frederic Boesel, Dustin Podell, Tim Dockhorn, Zion English, Kyle Lacey, Alex Goodwin, Yannik Marek and Robin Rombach<br />Stability AI<br />Published in arXiv, vol. 2403.03206, “Scaling Rectified Flow Transformers for High-Resolution Image Synthesis”, 2024<br />https://arxiv.org/abs/2403.03206</td></tr><tr><td>License</td><td>Stability AI Community License Agreement (https://huggingface.co/stabilityai/stable-diffusion-3-medium/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-stable-diffusion-v3-vae.fp16.safetensors" target="_blank">image-generation-stable-diffusion-v3-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3.5-large/resolve/main/transformer/diffusion_pytorch_model-00002-of-00002.safetensors?filename=image-generation-stable-diffusion-v3-5-large-transformer.nf4.bf16.safetensors" target="_blank">image-generation-stable-diffusion-v3-5-large-transformer.nf4.bf16.safetensors (6.31 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/text_encoder_2/model.fp16.safetensors?filename=text-encoding-open-clip-vit-g.fp16.safetensors" target="_blank">text-encoding-open-clip-vit-g.fp16.safetensors (1.39 GB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.nf4.fp16.safetensors" target="_blank">text-encoding-t5-xxl.nf4.fp16.safetensors (6.33 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/vocab.json?filename=text-encoding-open-clip-vit-g-tokenizer-vocab.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json" target="_blank">text-encoding-open-clip-vit-g-tokenizer-special-tokens-map.json (576.00 B)</a></li><li><a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium-diffusers/resolve/main/tokenizer_2/merges.txt?filename=text-encoding-open-clip-vit-g-tokenizer-merges.txt" target="_blank">text-encoding-open-clip-vit-g-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li></ol><p><strong>Total Size</strong>: 14.44 GB</p></td></tr><tr><td>Minimum VRAM</td><td>12.99 GB</td></tr></tbody></table>
<h3>flux-v1-dev</h3>
<table><tbody><tr><td>Name</td><td>FluxDev</td></tr><tr><td>Author</td><td>Black Forest Labs<br />Published in Black Forest Labs Blog, “Announcing Black Forest Labs”, 2024<br />https://blackforestlabs.ai/announcing-black-forest-labs/</td></tr><tr><td>License</td><td>FLUX.1 Non-Commercial License (https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-vae.fp16.safetensors" target="_blank">image-generation-flux-v1-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.fp16.safetensors" target="_blank">text-encoding-t5-xxl.fp16.safetensors (9.52 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/transformer/diffusion_pytorch_model-00001-of-00003.safetensors?filename=image-generation-flux-v1-dev-transformer.part-1.fp16.safetensors" target="_blank">image-generation-flux-v1-dev-transformer.part-1.fp16.safetensors (9.98 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/transformer/diffusion_pytorch_model-00002-of-00003.safetensors?filename=image-generation-flux-v1-dev-transformer.part-2.fp16.safetensors" target="_blank">image-generation-flux-v1-dev-transformer.part-2.fp16.safetensors (9.95 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/transformer/diffusion_pytorch_model-00003-of-00003.safetensors?filename=image-generation-flux-v1-dev-transformer.part-3.fp16.safetensors" target="_blank">image-generation-flux-v1-dev-transformer.part-3.fp16.safetensors (3.87 GB)</a></li></ol><p><strong>Total Size</strong>: 33.74 GB</p></td></tr><tr><td>Minimum VRAM</td><td>29.50 GB</td></tr></tbody></table>
<h3>flux-v1-dev-nf4</h3>
<table><tbody><tr><td>Name</td><td>FluxDevNF4</td></tr><tr><td>Author</td><td>Black Forest Labs<br />Published in Black Forest Labs Blog, “Announcing Black Forest Labs”, 2024<br />https://blackforestlabs.ai/announcing-black-forest-labs/</td></tr><tr><td>License</td><td>FLUX.1 Non-Commercial License (https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-vae.fp16.safetensors" target="_blank">image-generation-flux-v1-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.nf4.fp16.safetensors" target="_blank">text-encoding-t5-xxl.nf4.fp16.safetensors (6.33 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li><li><a href="https://huggingface.co/sayakpaul/flux.1-dev-nf4/resolve/main/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-dev-transformer.nf4.fp16.safetensors" target="_blank">image-generation-flux-v1-dev-transformer.nf4.fp16.safetensors (6.70 GB)</a></li></ol><p><strong>Total Size</strong>: 13.44 GB</p></td></tr><tr><td>Minimum VRAM</td><td>29.50 GB</td></tr></tbody></table>
<h3>flux-v1-dev-stoiqo-newreality-alpha-v2-nf4</h3>
<table><tbody><tr><td>Name</td><td>Stoiqo NewReality F1.D Alpha V2 (NF4) Image Generation</td></tr><tr><td>Author</td><td>Black Forest Labs<br />Published in Black Forest Labs Blog, “Announcing Black Forest Labs”, 2024<br />https://blackforestlabs.ai/announcing-black-forest-labs/<br />Finetuned by ALIENHAZE (https://civitai.com/user/ALIENHAZE)</td></tr><tr><td>License</td><td>FLUX.1 Non-Commercial License (https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-vae.fp16.safetensors" target="_blank">image-generation-flux-v1-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.nf4.fp16.safetensors" target="_blank">text-encoding-t5-xxl.nf4.fp16.safetensors (6.33 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/image-generation-flux-v1-dev-stoiqo-newreality-alpha-v2-transformer.nf4.fp16.safetensors" target="_blank">image-generation-flux-v1-dev-stoiqo-newreality-alpha-v2-transformer.nf4.fp16.safetensors (6.70 GB)</a></li></ol><p><strong>Total Size</strong>: 13.44 GB</p></td></tr><tr><td>Minimum VRAM</td><td>29.50 GB</td></tr></tbody></table>
<h3>flux-v1-schnell</h3>
<table><tbody><tr><td>Name</td><td>FluxSchnell</td></tr><tr><td>Author</td><td>Black Forest Labs<br />Published in Black Forest Labs Blog, “Announcing Black Forest Labs”, 2024<br />https://blackforestlabs.ai/announcing-black-forest-labs/</td></tr><tr><td>License</td><td>FLUX.1 Non-Commercial License (https://huggingface.co/black-forest-labs/FLUX.1-dev/blob/main/LICENSE.md)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/vae/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-vae.fp16.safetensors" target="_blank">image-generation-flux-v1-vae.fp16.safetensors (167.67 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/text_encoder/model.safetensors?filename=text-encoding-clip-vit-l.bf16.safetensors" target="_blank">text-encoding-clip-vit-l.bf16.safetensors (246.14 MB)</a></li><li><a href="https://huggingface.co/benjamin-paine/taproot-common/resolve/main/text-encoding-t5-xxl.fp16.safetensors" target="_blank">text-encoding-t5-xxl.fp16.safetensors (9.52 GB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/vocab.json?filename=text-encoding-clip-vit-l-tokenizer-vocab.json" target="_blank">text-encoding-clip-vit-l-tokenizer-vocab.json (1.06 MB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/special_tokens_map.json?filename=text-encoding-clip-vit-l-tokenizer-special-tokens-map.json" target="_blank">text-encoding-clip-vit-l-tokenizer-special-tokens-map.json (588.00 B)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer/merges.txt?filename=text-encoding-clip-vit-l-tokenizer-merges.txt" target="_blank">text-encoding-clip-vit-l-tokenizer-merges.txt (524.62 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/spiece.model?filename=text-encoding-t5-xxl-vocab.model" target="_blank">text-encoding-t5-xxl-vocab.model (791.66 KB)</a></li><li><a href="https://huggingface.co/black-forest-labs/FLUX.1-dev/resolve/main/tokenizer_2/special_tokens_map.json?filename=text-encoding-t5-xxl-special-tokens-map.json" target="_blank">text-encoding-t5-xxl-special-tokens-map.json (2.54 KB)</a></li><li><a href="https://huggingface.co/magespace/FLUX.1-schnell-bnb-nf4/resolve/main/transformer/diffusion_pytorch_model.safetensors?filename=image-generation-flux-v1-schnell-transformer.nf4.fp16.safetensors" target="_blank">image-generation-flux-v1-schnell-transformer.nf4.fp16.safetensors (6.69 GB)</a></li></ol><p><strong>Total Size</strong>: 16.63 GB</p></td></tr><tr><td>Minimum VRAM</td><td>29.50 GB</td></tr></tbody></table>
<h2>text-generation</h2>
<h3>llama-v3-8b</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Text Generation</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q8_0.gguf?filename=text-generation-llama-v3-8b-q8-0.gguf" target="_blank">text-generation-llama-v3-8b-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>9.64 GB</td></tr></tbody></table>
<h3>llama-v3-8b-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q6_K.gguf?filename=text-generation-llama-v3-8b-q6-k.gguf" target="_blank">text-generation-llama-v3-8b-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.10 GB</td></tr></tbody></table>
<h3>llama-v3-8b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q5_K_M.gguf?filename=text-generation-llama-v3-8b-q5-k-m.gguf" target="_blank">text-generation-llama-v3-8b-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>7.30 GB</td></tr></tbody></table>
<h3>llama-v3-8b-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q4_K_M.gguf?filename=text-generation-llama-v3-8b-q4-k-m.gguf" target="_blank">text-generation-llama-v3-8b-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>6.56 GB</td></tr></tbody></table>
<h3>llama-v3-8b-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Text Generation (Q3-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-GGUF/resolve/main/Meta-Llama-3-8B.Q3_K_M.gguf?filename=text-generation-llama-v3-8b-q3-k-m.gguf" target="_blank">text-generation-llama-v3-8b-q3-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.72 GB</td></tr></tbody></table>
<h3>llama-v3-8b-instruct</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Instruct Text Generation</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q8_0.gguf?filename=text-generation-llama-v3-8b-instruct-q8-0.gguf" target="_blank">text-generation-llama-v3-8b-instruct-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>9.64 GB</td></tr></tbody></table>
<h3>llama-v3-8b-instruct-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Instruct Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q6_K.gguf?filename=text-generation-llama-v3-8b-instruct-q6-k.gguf" target="_blank">text-generation-llama-v3-8b-instruct-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.10 GB</td></tr></tbody></table>
<h3>llama-v3-8b-instruct-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Instruct Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q5_K_M.gguf?filename=text-generation-llama-v3-8b-instruct-q5-k-m.gguf" target="_blank">text-generation-llama-v3-8b-instruct-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>7.30 GB</td></tr></tbody></table>
<h3>llama-v3-8b-instruct-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Instruct Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct-Q4_K_M.gguf?filename=text-generation-llama-v3-8b-instruct-q4-k-m.gguf" target="_blank">text-generation-llama-v3-8b-instruct-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>6.56 GB</td></tr></tbody></table>
<h3>llama-v3-8b-instruct-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.0 8B Instruct Text Generation (Q3-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3-8B-Instruct-GGUF/resolve/main/Meta-Llama-3-8B-Instruct.Q3_K_M.gguf?filename=text-generation-llama-v3-8b-instruct-q3-k-m.gguf" target="_blank">text-generation-llama-v3-8b-instruct-q3-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.72 GB</td></tr></tbody></table>
<h3>llama-v3-1-8b-instruct</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.1 8B Instruct Text Generation</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q8_0.gguf?filename=text-generation-llama-v3-1-8b-instruct-q8-0.gguf" target="_blank">text-generation-llama-v3-1-8b-instruct-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>9.64 GB</td></tr></tbody></table>
<h3>llama-v3-1-8b-instruct-q6-k (default)</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.1 8B Instruct Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q6_K.gguf?filename=text-generation-llama-v3-1-8b-instruct-q6-k.gguf" target="_blank">text-generation-llama-v3-1-8b-instruct-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.10 GB</td></tr></tbody></table>
<h3>llama-v3-1-8b-instruct-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.1 8B Instruct Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q5_K_M.gguf?filename=text-generation-llama-v3-1-8b-instruct-q5-k-m.gguf" target="_blank">text-generation-llama-v3-1-8b-instruct-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>7.30 GB</td></tr></tbody></table>
<h3>llama-v3-1-8b-instruct-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.1 8B Instruct Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q4_K_M.gguf?filename=text-generation-llama-v3-1-8b-instruct-q4-k-m.gguf" target="_blank">text-generation-llama-v3-1-8b-instruct-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>6.56 GB</td></tr></tbody></table>
<h3>llama-v3-1-8b-instruct-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.1 8B Instruct Text Generation (Q3-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/QuantFactory/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct.Q3_K_M.gguf?filename=text-generation-llama-v3-1-8b-instruct-q3-k-m.gguf" target="_blank">text-generation-llama-v3-1-8b-instruct-q3-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.72 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-f16.gguf?filename=text-generation-llama-v3-2-3b-instruct-f16.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-f16.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.04 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct-q8-0</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation (Q8-0)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q8_0.gguf?filename=text-generation-llama-v3-2-3b-instruct-q8-0.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.02 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q6_K.gguf?filename=text-generation-llama-v3-2-3b-instruct-q6-k.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>4.20 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q5_K_M.gguf?filename=text-generation-llama-v3-2-3b-instruct-q5-k-m.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>3.90 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q4_K_M.gguf?filename=text-generation-llama-v3-2-3b-instruct-q4-k-m.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>3.50 GB</td></tr></tbody></table>
<h3>llama-v3-2-3b-instruct-q3-k-l</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 3B Instruct Text Generation (Q3-K-L)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-3B-Instruct-GGUF/resolve/main/Llama-3.2-3B-Instruct-Q3_K_L.gguf?filename=text-generation-llama-v3-2-3b-instruct-q3-k-l.gguf" target="_blank">text-generation-llama-v3-2-3b-instruct-q3-k-l.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>3.10 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-f16.gguf?filename=text-generation-llama-v3-2-1b-instruct-f16.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-f16.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>3.60 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct-q8-0</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation (Q8-0)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q8_0.gguf?filename=text-generation-llama-v3-2-1b-instruct-q8-0.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>2.43 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q6_K.gguf?filename=text-generation-llama-v3-2-1b-instruct-q6-k.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>2.15 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q5_K_M.gguf?filename=text-generation-llama-v3-2-1b-instruct-q5-k-m.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>2.02 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q4_K_M.gguf?filename=text-generation-llama-v3-2-1b-instruct-q4-k-m.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>1.64 GB</td></tr></tbody></table>
<h3>llama-v3-2-1b-instruct-q3-k-l</h3>
<table><tbody><tr><td>Name</td><td>Llama V3.2 1B Instruct Text Generation (Q3-K-L)</td></tr><tr><td>Author</td><td>Meta AI<br />Published in arXiv, vol. 2407.21783, “The Llama 3 Herd of Models”, 2024<br />https://arxiv.org/abs/2407.21783</td></tr><tr><td>License</td><td>Meta Llama 3 Community License (https://www.llama.com/llama3/license/)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/bartowski/Llama-3.2-1B-Instruct-GGUF/resolve/main/Llama-3.2-1B-Instruct-Q3_K_L.gguf?filename=text-generation-llama-v3-2-1b-instruct-q3-k-l.gguf" target="_blank">text-generation-llama-v3-2-1b-instruct-q3-k-l.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>1.58 GB</td></tr></tbody></table>
<h3>zephyr-7b-alpha</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B α Text Generation (Q8)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q8_0.gguf?filename=text-generation-zephyr-alpha-7b-q8-0.gguf" target="_blank">text-generation-zephyr-alpha-7b-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>9.40 GB</td></tr></tbody></table>
<h3>zephyr-7b-alpha-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B α Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q6_K.gguf?filename=text-generation-zephyr-alpha-7b-q6-k.gguf" target="_blank">text-generation-zephyr-alpha-7b-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.20 GB</td></tr></tbody></table>
<h3>zephyr-7b-alpha-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B α Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q5_K_M.gguf?filename=text-generation-zephyr-alpha-7b-q5-k-m.gguf" target="_blank">text-generation-zephyr-alpha-7b-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>7.25 GB</td></tr></tbody></table>
<h3>zephyr-7b-alpha-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B α Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q4_K_M.gguf?filename=text-generation-zephyr-alpha-7b-q4-k-m.gguf" target="_blank">text-generation-zephyr-alpha-7b-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>6.30 GB</td></tr></tbody></table>
<h3>zephyr-7b-alpha-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B α Text Generation (Q3-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-alpha-GGUF/resolve/main/zephyr-7b-alpha.Q3_K_M.gguf?filename=text-generation-zephyr-alpha-7b-q3-k-m.gguf" target="_blank">text-generation-zephyr-alpha-7b-q3-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.35 GB</td></tr></tbody></table>
<h3>zephyr-7b-beta</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B β Text Generation</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q8_0.gguf?filename=text-generation-zephyr-beta-7b-q8-0.gguf" target="_blank">text-generation-zephyr-beta-7b-q8-0.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>9.40 GB</td></tr></tbody></table>
<h3>zephyr-7b-beta-q6-k</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B β Text Generation (Q6-K)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q6_K.gguf?filename=text-generation-zephyr-beta-7b-q6-k.gguf" target="_blank">text-generation-zephyr-beta-7b-q6-k.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>8.20 GB</td></tr></tbody></table>
<h3>zephyr-7b-beta-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B β Text Generation (Q5-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q5_K_M.gguf?filename=text-generation-zephyr-beta-7b-q5-k-m.gguf" target="_blank">text-generation-zephyr-beta-7b-q5-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>7.25 GB</td></tr></tbody></table>
<h3>zephyr-7b-beta-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B β Text Generation (Q4-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q4_K_M.gguf?filename=text-generation-zephyr-beta-7b-q4-k-m.gguf" target="_blank">text-generation-zephyr-beta-7b-q4-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>6.30 GB</td></tr></tbody></table>
<h3>zephyr-7b-beta-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>Zephyr 7B β Text Generation (Q3-K-M)</td></tr><tr><td>Author</td><td>Lewis Tunstall, Edward Beeching, Nathan Lambert, Nazneen Rajani, Kashif Rasul, Younes Belkada, Shengyi Huang, Leandro von Werra, Clémentine Fourrier, Nathan Habib, Nathan Sarrazin, Omar Sansevier, Alexander M. Rush and Thomas Wolf<br />Published in arXiv, vol. 2310.16944, “Zephyr: Direct Distillation of LM Alignment”, 2023<br />https://arxiv.org/abs/2310.16944</td></tr><tr><td>License</td><td>MIT License (https://opensource.org/licenses/MIT)</td></tr><tr><td>Files</td><td><a href="https://huggingface.co/TheBloke/zephyr-7B-beta-GGUF/resolve/main/zephyr-7b-beta.Q3_K_M.gguf?filename=text-generation-zephyr-beta-7b-q3-k-m.gguf" target="_blank">text-generation-zephyr-beta-7b-q3-k-m.gguf</a></td></tr><tr><td>Minimum VRAM</td><td>5.35 GB</td></tr></tbody></table>
<h2>visual-question-answering</h2>
<h3>llava-v1-5-7b</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/llava-1.5-7b-f16.gguf?filename=visual-question-answering-llava-v1-5-7b.fp16.gguf" target="_blank">visual-question-answering-llava-v1-5-7b.fp16.gguf (13.48 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 14.10 GB</p></td></tr><tr><td>Minimum VRAM</td><td>15.80 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q8</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q8-0) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/llava-1.5-7b-q8_0.gguf?filename=visual-question-answering-llava-v1-5-7b-q8-0.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q8-0.gguf (7.16 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 7.79 GB</p></td></tr><tr><td>Minimum VRAM</td><td>9.90 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q6-k</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q6-K) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q6_K.gguf?filename=visual-question-answering-llava-v1-5-7b-q6-k.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q6-k.gguf (5.53 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 6.15 GB</p></td></tr><tr><td>Minimum VRAM</td><td>8.40 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q5-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q5_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q5-k-m.gguf (4.78 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 5.41 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.71 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q4-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q4_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q4-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q4-k-m.gguf (4.08 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 4.71 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.04 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q3-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q3_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q3-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q3-k-m.gguf (3.30 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 3.92 GB</p></td></tr><tr><td>Minimum VRAM</td><td>6.33 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q8-0) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q8_0.gguf?filename=visual-question-answering-llava-v1-5-13b-q8-0.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q8-0.gguf (13.83 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 14.48 GB</p></td></tr><tr><td>Minimum VRAM</td><td>17.51 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q6-k</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q6-K) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q6_K.gguf?filename=visual-question-answering-llava-v1-5-13b-q6-k.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q6-k.gguf (10.68 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 11.32 GB</p></td></tr><tr><td>Minimum VRAM</td><td>14.54 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q5-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q5_K_M.gguf?filename=visual-question-answering-llava-v1-5-13b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q5-k-m.gguf (9.23 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 9.88 GB</p></td></tr><tr><td>Minimum VRAM</td><td>13.17 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q4-0</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q4-0) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q4_0.gguf?filename=visual-question-answering-llava-v1-5-13b-q4-0.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q4-0.gguf (7.37 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 8.01 GB</p></td></tr><tr><td>Minimum VRAM</td><td>11.48 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q5-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q5_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q5-k-m.gguf (24.32 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 25.02 GB</p></td></tr><tr><td>Minimum VRAM</td><td>24.96 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q4-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q4_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q4-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q4-k-m.gguf (20.66 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 21.36 GB</p></td></tr><tr><td>Minimum VRAM</td><td>21.88 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q3-K-M) Visual Question Answering</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q3_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q3-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q3-k-m.gguf (16.65 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 17.35 GB</p></td></tr><tr><td>Minimum VRAM</td><td>18.06 GB</td></tr></tbody></table>
<h3>moondream-v2 (default)</h3>
<table><tbody><tr><td>Name</td><td>Moondream V2 Visual Question Answering</td></tr><tr><td>Author</td><td>Vikhyat Korrapati<br />Published in Hugging Face, vol. 10.57967/hf/3219, “Moondream2”, 2024<br />https://huggingface.co/vikhyatk/moondream2</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream2-text-model-f16.gguf?filename=visual-question-answering-moondream-v2.fp16.gguf" target="_blank">visual-question-answering-moondream-v2.fp16.gguf (2.84 GB)</a></li><li><a href="https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream2-mmproj-f16.gguf?filename=image-encoding-clip-moondream-v2-mmproj.fp16.gguf" target="_blank">image-encoding-clip-moondream-v2-mmproj.fp16.gguf (909.78 MB)</a></li></ol><p><strong>Total Size</strong>: 3.75 GB</p></td></tr><tr><td>Minimum VRAM</td><td>4.44 GB</td></tr></tbody></table>
<h2>image-captioning</h2>
<h3>llava-v1-5-7b</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/llava-1.5-7b-f16.gguf?filename=visual-question-answering-llava-v1-5-7b.fp16.gguf" target="_blank">visual-question-answering-llava-v1-5-7b.fp16.gguf (13.48 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 14.10 GB</p></td></tr><tr><td>Minimum VRAM</td><td>15.80 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q8</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q8-0) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/llava-1.5-7b-q8_0.gguf?filename=visual-question-answering-llava-v1-5-7b-q8-0.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q8-0.gguf (7.16 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 7.79 GB</p></td></tr><tr><td>Minimum VRAM</td><td>9.90 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q6-k</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q6-K) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q6_K.gguf?filename=visual-question-answering-llava-v1-5-7b-q6-k.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q6-k.gguf (5.53 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 6.15 GB</p></td></tr><tr><td>Minimum VRAM</td><td>8.40 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q5-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q5_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q5-k-m.gguf (4.78 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 5.41 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.71 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q4-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q4_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q4-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q4-k-m.gguf (4.08 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 4.71 GB</p></td></tr><tr><td>Minimum VRAM</td><td>7.04 GB</td></tr></tbody></table>
<h3>llava-v1-5-7b-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.5 7B (Q3-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/second-state/Llava-v1.5-7B-GGUF/resolve/main/llava-v1.5-7b-Q3_K_M.gguf?filename=visual-question-answering-llava-v1-5-7b-q3-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-7b-q3-k-m.gguf (3.30 GB)</a></li><li><a href="https://huggingface.co/xaskasdf/llava-1.5-7b-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-7b.fp16.gguf (624.43 MB)</a></li></ol><p><strong>Total Size</strong>: 3.92 GB</p></td></tr><tr><td>Minimum VRAM</td><td>6.33 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q8-0) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q8_0.gguf?filename=visual-question-answering-llava-v1-5-13b-q8-0.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q8-0.gguf (13.83 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 14.48 GB</p></td></tr><tr><td>Minimum VRAM</td><td>17.51 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q6-k</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q6-K) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q6_K.gguf?filename=visual-question-answering-llava-v1-5-13b-q6-k.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q6-k.gguf (10.68 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 11.32 GB</p></td></tr><tr><td>Minimum VRAM</td><td>14.54 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q5-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q5_K_M.gguf?filename=visual-question-answering-llava-v1-5-13b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q5-k-m.gguf (9.23 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 9.88 GB</p></td></tr><tr><td>Minimum VRAM</td><td>13.17 GB</td></tr></tbody></table>
<h3>llava-v1-5-13b-q4-0</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.51 13B (Q4-0) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/llava-v1.5-13b-Q4_0.gguf?filename=visual-question-answering-llava-v1-5-13b-q4-0.gguf" target="_blank">visual-question-answering-llava-v1-5-13b-q4-0.gguf (7.37 GB)</a></li><li><a href="https://huggingface.co/PsiPi/liuhaotian_llava-v1.5-13b-GGUF/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-5-13b.fp16.gguf (645.41 MB)</a></li></ol><p><strong>Total Size</strong>: 8.01 GB</p></td></tr><tr><td>Minimum VRAM</td><td>11.48 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q5-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q5-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q5_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q5-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q5-k-m.gguf (24.32 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 25.02 GB</p></td></tr><tr><td>Minimum VRAM</td><td>24.96 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q4-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q4-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q4_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q4-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q4-k-m.gguf (20.66 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 21.36 GB</p></td></tr><tr><td>Minimum VRAM</td><td>21.88 GB</td></tr></tbody></table>
<h3>llava-v1-6-34b-q3-k-m</h3>
<table><tbody><tr><td>Name</td><td>LLaVA V1.6 34B (Q3-K-M) Image Captioning</td></tr><tr><td>Author</td><td>Haotian Liu, Chunyuan Li, Li Yuheng and Yong Jae Lee<br />Published in arXiv, vol. 2310.03744, “Improved Baselines with Visual Instruction Tuning”, 2023<br />https://arxiv.org/abs/2310.03744</td></tr><tr><td>License</td><td>Meta Llama 2 Community License (https://www.llama.com/llama2/license/)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-GGUF/resolve/main/llava-v1.6-34b.Q3_K_M.gguf?filename=visual-question-answering-llava-v1-6-34b-q3-k-m.gguf" target="_blank">visual-question-answering-llava-v1-6-34b-q3-k-m.gguf (16.65 GB)</a></li><li><a href="https://huggingface.co/cjpais/llava-v1.6-34B-gguf/resolve/main/mmproj-model-f16.gguf?filename=image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf" target="_blank">image-encoding-clip-llava-mmproj-v1-6-34b.fp16.gguf (699.99 MB)</a></li></ol><p><strong>Total Size</strong>: 17.35 GB</p></td></tr><tr><td>Minimum VRAM</td><td>18.06 GB</td></tr></tbody></table>
<h3>moondream-v2 (default)</h3>
<table><tbody><tr><td>Name</td><td>Moondream V2 Image Captioning</td></tr><tr><td>Author</td><td>Vikhyat Korrapati<br />Published in Hugging Face, vol. 10.57967/hf/3219, “Moondream2”, 2024<br />https://huggingface.co/vikhyatk/moondream2</td></tr><tr><td>License</td><td>Apache License 2.0 (https://www.apache.org/licenses/LICENSE-2.0)</td></tr><tr><td>Files</td><td><ol><li><a href="https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream2-text-model-f16.gguf?filename=visual-question-answering-moondream-v2.fp16.gguf" target="_blank">visual-question-answering-moondream-v2.fp16.gguf (2.84 GB)</a></li><li><a href="https://huggingface.co/vikhyatk/moondream2/resolve/main/moondream2-mmproj-f16.gguf?filename=image-encoding-clip-moondream-v2-mmproj.fp16.gguf" target="_blank">image-encoding-clip-moondream-v2-mmproj.fp16.gguf (909.78 MB)</a></li></ol><p><strong>Total Size</strong>: 3.75 GB</p></td></tr><tr><td>Minimum VRAM</td><td>4.44 GB</td></tr></tbody></table>
